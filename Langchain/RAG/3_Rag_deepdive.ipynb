{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install -r ../requirements.txt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: langchain-openai in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from -r ../requirements.txt (line 1)) (0.1.21)\nRequirement already satisfied: python-dotenv==1.0.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from -r ../requirements.txt (line 2)) (1.0.1)\nRequirement already satisfied: langchain in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from -r ../requirements.txt (line 3)) (0.2.13)\nRequirement already satisfied: wikipedia==1.4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from -r ../requirements.txt (line 4)) (1.4.0)\nRequirement already satisfied: tavily-python in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from -r ../requirements.txt (line 5)) (0.3.9)\nRequirement already satisfied: sentence-transformers in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from -r ../requirements.txt (line 6)) (3.0.1)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from -r ../requirements.txt (line 7)) (4.66.4)\nRequirement already satisfied: beautifulsoup4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from wikipedia==1.4.0->-r ../requirements.txt (line 4)) (4.12.3)\nRequirement already satisfied: requests<3.0.0,>=2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from wikipedia==1.4.0->-r ../requirements.txt (line 4)) (2.32.3)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.29 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-openai->-r ../requirements.txt (line 1)) (0.2.30)\nRequirement already satisfied: openai<2.0.0,>=1.40.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-openai->-r ../requirements.txt (line 1)) (1.40.3)\nRequirement already satisfied: tiktoken<1,>=0.7 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-openai->-r ../requirements.txt (line 1)) (0.7.0)\nRequirement already satisfied: PyYAML>=5.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain->-r ../requirements.txt (line 3)) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain->-r ../requirements.txt (line 3)) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain->-r ../requirements.txt (line 3)) (3.10.3)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain->-r ../requirements.txt (line 3)) (4.0.3)\nRequirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain->-r ../requirements.txt (line 3)) (0.2.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain->-r ../requirements.txt (line 3)) (0.1.98)\nRequirement already satisfied: numpy<2,>=1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain->-r ../requirements.txt (line 3)) (1.23.5)\nRequirement already satisfied: pydantic<3,>=1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain->-r ../requirements.txt (line 3)) (2.8.2)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain->-r ../requirements.txt (line 3)) (8.5.0)\nRequirement already satisfied: httpx in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tavily-python->-r ../requirements.txt (line 5)) (0.27.0)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sentence-transformers->-r ../requirements.txt (line 6)) (4.44.2)\nRequirement already satisfied: torch>=1.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sentence-transformers->-r ../requirements.txt (line 6)) (2.4.1)\nRequirement already satisfied: scikit-learn in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sentence-transformers->-r ../requirements.txt (line 6)) (1.5.0)\nRequirement already satisfied: scipy in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sentence-transformers->-r ../requirements.txt (line 6)) (1.13.1)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sentence-transformers->-r ../requirements.txt (line 6)) (0.24.6)\nRequirement already satisfied: Pillow in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sentence-transformers->-r ../requirements.txt (line 6)) (10.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ../requirements.txt (line 3)) (2.3.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ../requirements.txt (line 3)) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ../requirements.txt (line 3)) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ../requirements.txt (line 3)) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ../requirements.txt (line 3)) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ../requirements.txt (line 3)) (1.9.4)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r ../requirements.txt (line 6)) (3.14.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r ../requirements.txt (line 6)) (2023.10.0)\nRequirement already satisfied: packaging>=20.9 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r ../requirements.txt (line 6)) (24.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r ../requirements.txt (line 6)) (4.12.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai->-r ../requirements.txt (line 1)) (1.33)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r ../requirements.txt (line 3)) (3.10.7)\nRequirement already satisfied: anyio<5,>=3.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai->-r ../requirements.txt (line 1)) (4.4.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai->-r ../requirements.txt (line 1)) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai->-r ../requirements.txt (line 1)) (0.5.0)\nRequirement already satisfied: sniffio in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai->-r ../requirements.txt (line 1)) (1.3.1)\nRequirement already satisfied: certifi in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx->tavily-python->-r ../requirements.txt (line 5)) (2024.6.2)\nRequirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx->tavily-python->-r ../requirements.txt (line 5)) (1.0.5)\nRequirement already satisfied: idna in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx->tavily-python->-r ../requirements.txt (line 5)) (3.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpcore==1.*->httpx->tavily-python->-r ../requirements.txt (line 5)) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<3,>=1->langchain->-r ../requirements.txt (line 3)) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<3,>=1->langchain->-r ../requirements.txt (line 3)) (2.20.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0->-r ../requirements.txt (line 4)) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0->-r ../requirements.txt (line 4)) (2.2.1)\nRequirement already satisfied: greenlet!=0.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain->-r ../requirements.txt (line 3)) (3.0.3)\nRequirement already satisfied: regex>=2022.1.18 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai->-r ../requirements.txt (line 1)) (2024.7.24)\nRequirement already satisfied: sympy in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (1.13.2)\nRequirement already satisfied: networkx in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (3.3)\nRequirement already satisfied: jinja2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (12.6.68)\nRequirement already satisfied: safetensors>=0.4.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->-r ../requirements.txt (line 6)) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->-r ../requirements.txt (line 6)) (0.19.1)\nRequirement already satisfied: soupsieve>1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from beautifulsoup4->wikipedia==1.4.0->-r ../requirements.txt (line 4)) (2.5)\nRequirement already satisfied: joblib>=1.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->-r ../requirements.txt (line 6)) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->-r ../requirements.txt (line 6)) (3.5.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai->-r ../requirements.txt (line 1)) (1.2.0)\nRequirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.29->langchain-openai->-r ../requirements.txt (line 1)) (3.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers->-r ../requirements.txt (line 6)) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Env Variables and Secrets"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv('../../../azure.env')\n",
        "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-06-01\"\n",
        "os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"] = 'gpt-4o-mini'\n",
        "os.environ[\"AZURE_OPENAI_MODEL_VERSION\"] = '2024-06-01'\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1727552963272
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import packages"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_core.vectorstores import InMemoryVectorStore"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727552968773
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AzureChatOpenAI(\n",
        "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
        "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
        "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
        "    model_version=os.environ['AZURE_OPENAI_MODEL_VERSION']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1727552972174
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "embeddings = AzureOpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
        "    # dimensions: Optional[int] = None, # Can specify dimensions with new text-embedding-3 models\n",
        "    # azure_endpoint=\"https://<your-endpoint>.openai.azure.com/\", If not provided, will read env variable AZURE_OPENAI_ENDPOINT\n",
        "    # api_key=... # Can provide an API key directly. If missing read env variable AZURE_OPENAI_API_KEY\n",
        "    # openai_api_version=..., # If not provided, will read env variable AZURE_OPENAI_API_VERSION\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727552974245
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory containing the text file and the persistent directory\n",
        "current_dir = os.path.dirname(os.path.commonpath('.'))\n",
        "books_dir = os.path.join(current_dir, \"books_small\")\n",
        "print(f\"Books directory: {books_dir}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Books directory: books_small\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727552979070
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the books directory exists\n",
        "if not os.path.exists(books_dir):\n",
        "    raise FileNotFoundError(\n",
        "        f\"The directory {books_dir} does not exist. Please check the path.\"\n",
        "    )\n",
        "\n",
        "# List all text files in the directory\n",
        "book_files = [f for f in os.listdir(books_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "# Read the text content from each file and store it with metadata\n",
        "documents = []\n",
        "for book_file in book_files:\n",
        "    file_path = os.path.join(books_dir, book_file)\n",
        "    loader = TextLoader(file_path)\n",
        "    book_docs = loader.load()\n",
        "    for doc in book_docs:\n",
        "        # Add metadata to each document indicating its source\n",
        "        doc.metadata = {\"source\": book_file}\n",
        "        documents.append(doc)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727553019787
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create and persist vector store\n",
        "def create_vector_store(docs, store_name):\n",
        "    # Create the vector store and persist it automatically\n",
        "    print(f\"\\n--- Creating vector store {store_name} ---\")\n",
        "    vectorstore = InMemoryVectorStore.from_documents(\n",
        "        documents=docs,\n",
        "        embedding=embeddings,\n",
        "    )\n",
        "    print(\"\\n--- Finished creating vector store ---\")\n",
        "    return vectorstore"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727553036804
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to query a vector store\n",
        "def query_vector_store(vcs,store_name, query,search_kwargs,search_type):\n",
        "    print(f\"\\n--- Querying the Vector Store {store_name} ---\")\n",
        "    # Use the vectorstore as a retriever\n",
        "    retriever = vcs.as_retriever(\n",
        "        search_type=search_type,\n",
        "        search_kwargs=search_kwargs)\n",
        "\n",
        "    # Retrieve the most similar text\n",
        "    retrieved_documents = retriever.invoke(query)\n",
        "\n",
        "    # Display the relevant results with metadata\n",
        "    print(\"\\n--- Relevant Documents ---\")\n",
        "    for i, doc in enumerate(retrieved_documents, 1):\n",
        "        print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
        "        if doc.metadata:\n",
        "            print(f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\")"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727553403272
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the user's question\n",
        "query = \"How did Juliet die?\"\n",
        "# 4. Recursive Character-based Splitting\n",
        "# Attempts to split text at natural boundaries (sentences, paragraphs) within character limit.\n",
        "# Balances between maintaining coherence and adhering to character limits.\n",
        "print(\"\\n--- Using Recursive Character-based Splitting ---\")\n",
        "rec_char_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=100)\n",
        "rec_char_docs = rec_char_splitter.split_documents(documents)\n",
        "vcs = create_vector_store(rec_char_docs, \"db_rec_char\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n--- Using Recursive Character-based Splitting ---\n\n--- Creating vector store db_rec_char ---\n\n--- Finished creating vector store ---\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727553561122
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Similarity Search\n",
        "# This method retrieves documents based on vector similarity.\n",
        "# It finds the most similar documents to the query vector based on cosine similarity.\n",
        "# Use this when you want to retrieve the top k most similar documents.\n",
        "print(\"\\n--- Using Similarity Search ---\")\n",
        "query_vector_store(vcs,\"chroma_db_with_metadata\", query,\n",
        "                    search_type=\"similarity\", search_kwargs={\"k\": 3})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n--- Using Similarity Search ---\n\n--- Querying the Vector Store chroma_db_with_metadata ---\n\n--- Relevant Documents ---\nDocument 1:\nNURSE.\nI saw the wound, I saw it with mine eyes,\nGod save the mark!—here on his manly breast.\nA piteous corse, a bloody piteous corse;\nPale, pale as ashes, all bedaub’d in blood,\nAll in gore-blood. I swounded at the sight.\n\nJULIET.\nO, break, my heart. Poor bankrout, break at once.\nTo prison, eyes; ne’er look on liberty.\nVile earth to earth resign; end motion here,\nAnd thou and Romeo press one heavy bier.\n\nNURSE.\nO Tybalt, Tybalt, the best friend I had.\nO courteous Tybalt, honest gentleman!\nThat ever I should live to see thee dead.\n\nJULIET.\nWhat storm is this that blows so contrary?\nIs Romeo slaughter’d and is Tybalt dead?\nMy dearest cousin, and my dearer lord?\nThen dreadful trumpet sound the general doom,\nFor who is living, if those two are gone?\n\nNURSE.\nTybalt is gone, and Romeo banished,\nRomeo that kill’d him, he is banished.\n\nJULIET.\nO God! Did Romeo’s hand shed Tybalt’s blood?\n\nNURSE.\nIt did, it did; alas the day, it did.\n\nSource: romeo_and_juliet.txt\n\nDocument 2:\n[_Exeunt Lady Capulet and Nurse._]\n\nJULIET.\nFarewell. God knows when we shall meet again.\nI have a faint cold fear thrills through my veins\nThat almost freezes up the heat of life.\nI’ll call them back again to comfort me.\nNurse!—What should she do here?\nMy dismal scene I needs must act alone.\nCome, vial.\nWhat if this mixture do not work at all?\nShall I be married then tomorrow morning?\nNo, No! This shall forbid it. Lie thou there.\n\n [_Laying down her dagger._]\n\nSource: romeo_and_juliet.txt\n\nDocument 3:\nJULIET.\nO God! Did Romeo’s hand shed Tybalt’s blood?\n\nNURSE.\nIt did, it did; alas the day, it did.\n\nJULIET.\nO serpent heart, hid with a flowering face!\nDid ever dragon keep so fair a cave?\nBeautiful tyrant, fiend angelical,\nDove-feather’d raven, wolvish-ravening lamb!\nDespised substance of divinest show!\nJust opposite to what thou justly seem’st,\nA damned saint, an honourable villain!\nO nature, what hadst thou to do in hell\nWhen thou didst bower the spirit of a fiend\nIn mortal paradise of such sweet flesh?\nWas ever book containing such vile matter\nSo fairly bound? O, that deceit should dwell\nIn such a gorgeous palace.\n\nNURSE.\nThere’s no trust,\nNo faith, no honesty in men. All perjur’d,\nAll forsworn, all naught, all dissemblers.\nAh, where’s my man? Give me some aqua vitae.\nThese griefs, these woes, these sorrows make me old.\nShame come to Romeo.\n\nSource: romeo_and_juliet.txt\n\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727553641687
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Max Marginal Relevance (MMR)\n",
        "# This method balances between selecting documents that are relevant to the query and diverse among themselves.\n",
        "# 'fetch_k' specifies the number of documents to initially fetch based on similarity.\n",
        "# 'lambda_mult' controls the diversity of the results: 1 for minimum diversity, 0 for maximum.\n",
        "# Use this when you want to avoid redundancy and retrieve diverse yet relevant documents.\n",
        "# Note: Relevance measures how closely documents match the query.\n",
        "# Note: Diversity ensures that the retrieved documents are not too similar to each other,\n",
        "#       providing a broader range of information.\n",
        "print(\"\\n--- Using Max Marginal Relevance (MMR) ---\")\n",
        "query_vector_store(vcs,\"chroma_db_with_metadata\", query,\n",
        "                    search_type=\"mmr\", \n",
        "                    search_kwargs={\"k\": 3, \"fetch_k\": 20, \"lambda_mult\": 0.5})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n--- Using Max Marginal Relevance (MMR) ---\n\n--- Querying the Vector Store chroma_db_with_metadata ---\n\n--- Relevant Documents ---\nDocument 1:\nNURSE.\nI saw the wound, I saw it with mine eyes,\nGod save the mark!—here on his manly breast.\nA piteous corse, a bloody piteous corse;\nPale, pale as ashes, all bedaub’d in blood,\nAll in gore-blood. I swounded at the sight.\n\nJULIET.\nO, break, my heart. Poor bankrout, break at once.\nTo prison, eyes; ne’er look on liberty.\nVile earth to earth resign; end motion here,\nAnd thou and Romeo press one heavy bier.\n\nNURSE.\nO Tybalt, Tybalt, the best friend I had.\nO courteous Tybalt, honest gentleman!\nThat ever I should live to see thee dead.\n\nJULIET.\nWhat storm is this that blows so contrary?\nIs Romeo slaughter’d and is Tybalt dead?\nMy dearest cousin, and my dearer lord?\nThen dreadful trumpet sound the general doom,\nFor who is living, if those two are gone?\n\nNURSE.\nTybalt is gone, and Romeo banished,\nRomeo that kill’d him, he is banished.\n\nJULIET.\nO God! Did Romeo’s hand shed Tybalt’s blood?\n\nNURSE.\nIt did, it did; alas the day, it did.\n\nSource: romeo_and_juliet.txt\n\nDocument 2:\nBeing the time the potion’s force should cease.\nBut he which bore my letter, Friar John,\nWas stay’d by accident; and yesternight\nReturn’d my letter back. Then all alone\nAt the prefixed hour of her waking\nCame I to take her from her kindred’s vault,\nMeaning to keep her closely at my cell\nTill I conveniently could send to Romeo.\nBut when I came, some minute ere the time\nOf her awaking, here untimely lay\nThe noble Paris and true Romeo dead.\nShe wakes; and I entreated her come forth\nAnd bear this work of heaven with patience.\nBut then a noise did scare me from the tomb;\nAnd she, too desperate, would not go with me,\nBut, as it seems, did violence on herself.\nAll this I know; and to the marriage\nHer Nurse is privy. And if ought in this\nMiscarried by my fault, let my old life\nBe sacrific’d, some hour before his time,\nUnto the rigour of severest law.\n\nSource: romeo_and_juliet.txt\n\nDocument 3:\n[_Exeunt Lady Capulet and Nurse._]\n\nJULIET.\nFarewell. God knows when we shall meet again.\nI have a faint cold fear thrills through my veins\nThat almost freezes up the heat of life.\nI’ll call them back again to comfort me.\nNurse!—What should she do here?\nMy dismal scene I needs must act alone.\nCome, vial.\nWhat if this mixture do not work at all?\nShall I be married then tomorrow morning?\nNo, No! This shall forbid it. Lie thou there.\n\n [_Laying down her dagger._]\n\nSource: romeo_and_juliet.txt\n\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727553690605
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}